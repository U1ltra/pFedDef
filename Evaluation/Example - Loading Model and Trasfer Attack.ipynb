{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Documents/jiarui/code/pFedDef\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/Documents/jiarui/code/pFedDef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import General Libraries\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import FedEM based Libraries\n",
    "from utils.utils import *\n",
    "from utils.constants import *\n",
    "from utils.args import *\n",
    "from run_experiment import *\n",
    "from models import *\n",
    "\n",
    "# Import Transfer Attack\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "from transfer_attacks.Transferer import *\n",
    "from transfer_attacks.Args import *\n",
    "from transfer_attacks.TA_utils import *\n",
    "from transfer_attacks.Boundary_Transferer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 141.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:09<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Test Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 2.299 | Train Acc: 10.514% |Test Loss: 2.298 | Test Acc: 11.018% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "# Generating Empty Aggregator to be loaded \n",
    "\n",
    "setting = 'FedAvg'\n",
    "\n",
    "if setting == 'FedEM':\n",
    "    nL = 3\n",
    "else:\n",
    "    nL = 1\n",
    "\n",
    "# Manually set argument parameters\n",
    "args_ = Args()\n",
    "args_.experiment = \"cifar10\"\n",
    "args_.method = setting\n",
    "args_.decentralized = False\n",
    "args_.sampling_rate = 1.0\n",
    "args_.input_dimension = None\n",
    "args_.output_dimension = None\n",
    "args_.n_learners= nL\n",
    "args_.n_rounds = 10\n",
    "args_.bz = 128\n",
    "args_.local_steps = 1\n",
    "args_.lr_lambda = 0\n",
    "args_.lr =0.03\n",
    "args_.lr_scheduler = 'multi_step'\n",
    "args_.log_freq = 10\n",
    "args_.device = 'cuda'\n",
    "args_.optimizer = 'sgd'\n",
    "args_.mu = 0\n",
    "args_.communication_probability = 0.1\n",
    "args_.q = 1\n",
    "args_.locally_tune_clients = False\n",
    "args_.seed = 1234\n",
    "args_.verbose = 1\n",
    "args_.save_path = 'weights/cifar/dummy/'\n",
    "args_.validation = False\n",
    "\n",
    "# Generate the dummy values here\n",
    "aggregator, clients = dummy_aggregator(args_, num_user=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Dataset from Clients\n",
    "# Combine Validation Data across all clients as test\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for i in range(len(clients)):\n",
    "    daniloader = clients[i].test_iterator\n",
    "    for (x,y,idx) in daniloader.dataset:\n",
    "        data_x.append(x)\n",
    "        data_y.append(y)\n",
    "\n",
    "data_x = torch.stack(data_x)\n",
    "try:\n",
    "    data_y = torch.stack(data_y)        \n",
    "except:\n",
    "    data_y = torch.FloatTensor(data_y) \n",
    "\n",
    "    \n",
    "# mask_cat = data_y==3\n",
    "# mask_dog = data_y==5\n",
    "# data_x = torch.cat(\n",
    "#     (data_x[mask_cat], data_x[mask_dog]),\n",
    "#     0\n",
    "# )\n",
    "# data_y = torch.cat(\n",
    "#     (data_y[mask_cat], data_y[mask_dog]),\n",
    "#     0\n",
    "# )\n",
    "    \n",
    "    \n",
    "dataloader = Custom_Dataloader(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model Weights\n",
    "num_models = 40\n",
    "\n",
    "root_path = \"/home/ubuntu/Documents/jiarui/experiments/FedAvg_adv/rep_atk/rep_scale0/weights\"\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "\n",
    "if setting == 'local':\n",
    "\n",
    "#     args_.save_path = 'weights/final/femnist/fig1_take3/local_benign/'\n",
    "    args_.save_path ='weights/final/femnist/fig1_take3/local_adv/'\n",
    "    aggregator.load_state(args_.save_path)\n",
    "    \n",
    "    model_weights = []\n",
    "#     weights = np.load(\"weights/final/femnist/fig1_take3/local_benign/train_client_weights.npy\")\n",
    "    weights = np.load('weights/final/femnist/fig1_take3/local_adv/train_client_weights.npy')\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        model_weights += [weights[i]]\n",
    "\n",
    "    # Generate the weights to test on as linear combinations of the model_weights\n",
    "    models_test = []\n",
    "\n",
    "    for i in range(num_models):\n",
    "        new_model = copy.deepcopy(aggregator.clients[i].learners_ensemble.learners[0].model)\n",
    "        new_model.eval()\n",
    "        models_test += [new_model]\n",
    "\n",
    "elif setting == 'FedAvg':\n",
    "    \n",
    "#     args_.save_path = 'weights/final/femnist/fig1_take3/fedavg_benign/'\n",
    "    args_.save_path = root_path\n",
    "    aggregator.load_state(args_.save_path)\n",
    "    \n",
    "    # This is where the models are stored -- one for each mixture --> learner.model for nn\n",
    "    hypotheses = aggregator.global_learners_ensemble.learners\n",
    "\n",
    "    # obtain the state dict for each of the weights \n",
    "    weights_h = []\n",
    "\n",
    "    for h in hypotheses:\n",
    "        weights_h += [h.model.state_dict()]\n",
    "\n",
    "#     weights = np.load(\"weights/final/femnist/fig1_take3/fedavg_benign/train_client_weights.npy\")\n",
    "    weights = np.load(f'{root_path}/train_client_weights.npy')\n",
    "    \n",
    "    # Set model weights\n",
    "    model_weights = []\n",
    "\n",
    "    for i in range(num_models):\n",
    "        model_weights += [weights[i]]\n",
    "\n",
    "    # Generate the weights to test on as linear combinations of the model_weights\n",
    "    models_test = []\n",
    "\n",
    "    for (w0) in model_weights:\n",
    "        # first make the model with empty weights\n",
    "        new_model = copy.deepcopy(hypotheses[0].model)\n",
    "        new_model.eval()\n",
    "        new_weight_dict = copy.deepcopy(weights_h[0])\n",
    "        for key in weights_h[0]:\n",
    "            new_weight_dict[key] = w0[0]*weights_h[0][key] \n",
    "        new_model.load_state_dict(new_weight_dict)\n",
    "        models_test += [new_model]\n",
    "\n",
    "elif setting == 'FedEM':\n",
    "    \n",
    "#     args_.save_path = 'weights/final/femnist/fig1_take3/fedem_benign/'\n",
    "#     args_.save_path = 'weights/final/femnist/fig1_take3/fedem_adv/'\n",
    "    args_.save_path = root_path\n",
    "    aggregator.load_state(args_.save_path)\n",
    "    \n",
    "    # This is where the models are stored -- one for each mixture --> learner.model for nn\n",
    "    hypotheses = aggregator.global_learners_ensemble.learners\n",
    "\n",
    "    # obtain the state dict for each of the weights \n",
    "    weights_h = []\n",
    "\n",
    "    for h in hypotheses:\n",
    "        weights_h += [h.model.state_dict()]\n",
    "\n",
    "#     weights = np.load(\"weights/final/femnist/fig1_take3/fedem_benign/train_client_weights.npy\")\n",
    "#     weights = np.load(\"weights/final/femnist/fig1_take3/fedem_adv/train_client_weights.npy\")\n",
    "    weights = np.load(f\"{root_path}/train_client_weights.npy\")\n",
    "\n",
    "    # Set model weights\n",
    "    model_weights = []\n",
    "\n",
    "    for i in range(num_models):\n",
    "        model_weights += [weights[i]]\n",
    "\n",
    "\n",
    "    # Generate the weights to test on as linear combinations of the model_weights\n",
    "    models_test = []\n",
    "\n",
    "    for (w0,w1,w2) in model_weights:\n",
    "        # first make the model with empty weights\n",
    "        new_model = copy.deepcopy(hypotheses[0].model)\n",
    "        new_model.eval()\n",
    "        new_weight_dict = copy.deepcopy(weights_h[0])\n",
    "        for key in weights_h[0]:\n",
    "#             print(key)\n",
    "#             print(weights_h[0][key])\n",
    "#             print(weights_h[1][key])\n",
    "#             print(weights_h[2][key])\n",
    "            new_weight_dict[key] = w0*weights_h[0][key] + w1*weights_h[1][key] + w2*weights_h[2][key]\n",
    "        new_model.load_state_dict(new_weight_dict)\n",
    "        models_test += [new_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will make a dictionary that will hold results\n",
    "logs_adv = []\n",
    "\n",
    "for i in range(num_models):\n",
    "    adv_dict = {}\n",
    "    adv_dict['orig_acc_transfers'] = None\n",
    "    adv_dict['orig_similarities'] = None\n",
    "    adv_dict['adv_acc_transfers'] = None\n",
    "    adv_dict['adv_similarities_target'] = None\n",
    "    adv_dict['adv_similarities_untarget'] = None\n",
    "    adv_dict['adv_target'] = None\n",
    "    adv_dict['adv_miss'] = None\n",
    "    adv_dict['metric_alignment'] = None\n",
    "    adv_dict['ib_distance_legit'] = None\n",
    "    adv_dict['ib_distance_adv'] = None\n",
    "\n",
    "    logs_adv += [adv_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Adv idx: 0\n",
      "\t Adv idx: 1\n",
      "\t Adv idx: 2\n",
      "\t Adv idx: 3\n",
      "\t Adv idx: 4\n",
      "\t Adv idx: 5\n",
      "\t Adv idx: 6\n",
      "\t Adv idx: 7\n",
      "\t Adv idx: 8\n",
      "\t Adv idx: 9\n",
      "\t Adv idx: 10\n",
      "\t Adv idx: 11\n",
      "\t Adv idx: 12\n",
      "\t Adv idx: 13\n",
      "\t Adv idx: 14\n",
      "\t Adv idx: 15\n",
      "\t Adv idx: 16\n",
      "\t Adv idx: 17\n",
      "\t Adv idx: 18\n",
      "\t Adv idx: 19\n",
      "\t Adv idx: 20\n",
      "\t Adv idx: 21\n",
      "\t Adv idx: 22\n",
      "\t Adv idx: 23\n",
      "\t Adv idx: 24\n",
      "\t Adv idx: 25\n",
      "\t Adv idx: 26\n",
      "\t Adv idx: 27\n",
      "\t Adv idx: 28\n",
      "\t Adv idx: 29\n",
      "\t Adv idx: 30\n",
      "\t Adv idx: 31\n",
      "\t Adv idx: 32\n",
      "\t Adv idx: 33\n",
      "\t Adv idx: 34\n",
      "\t Adv idx: 35\n",
      "\t Adv idx: 36\n",
      "\t Adv idx: 37\n",
      "\t Adv idx: 38\n",
      "\t Adv idx: 39\n"
     ]
    }
   ],
   "source": [
    "# Perform transfer attack from one client to another and record stats\n",
    "\n",
    "# Run Measurements for both targetted and untargeted analysis\n",
    "new_num_models = len(models_test)\n",
    "victim_idxs = range(new_num_models)\n",
    "custom_batch_size = 500\n",
    "eps = 4.5\n",
    "\n",
    "\n",
    "for adv_idx in victim_idxs:\n",
    "    print(\"\\t Adv idx:\", adv_idx)\n",
    "    \n",
    "    dataloader = load_client_data(\n",
    "        clients = clients, \n",
    "        c_id = adv_idx, \n",
    "        mode = 'test',\n",
    "        switch = False\n",
    "    ) # or test/train\n",
    "    \n",
    "    batch_size = min(custom_batch_size, dataloader.y_data.shape[0])\n",
    "    \n",
    "    t1 = Transferer(models_list=models_test, dataloader=dataloader)\n",
    "    t1.generate_victims(victim_idxs)\n",
    "    \n",
    "    # Perform Attacks Targeted\n",
    "    t1.atk_params = PGD_Params()\n",
    "    t1.atk_params.set_params(\n",
    "        batch_size=batch_size,\n",
    "        iteration = 10,\n",
    "        target = 3, \n",
    "        x_val_min = torch.min(data_x), \n",
    "        x_val_max = torch.max(data_x),\n",
    "        step_size = 0.01, \n",
    "        step_norm = \"inf\", \n",
    "        eps = eps, \n",
    "        eps_norm = 2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    t1.generate_advNN(adv_idx)\n",
    "    t1.generate_xadv(atk_type = \"pgd\")\n",
    "    t1.send_to_victims(victim_idxs)\n",
    "\n",
    "    # Log Performance\n",
    "    logs_adv[adv_idx]['orig_acc_transfers'] = copy.deepcopy(t1.orig_acc_transfers)\n",
    "    logs_adv[adv_idx]['orig_similarities'] = copy.deepcopy(t1.orig_similarities)\n",
    "    logs_adv[adv_idx]['adv_acc_transfers'] = copy.deepcopy(t1.adv_acc_transfers)\n",
    "    logs_adv[adv_idx]['adv_similarities_target'] = copy.deepcopy(t1.adv_similarities)        \n",
    "    logs_adv[adv_idx]['adv_target'] = copy.deepcopy(t1.adv_target_hit)\n",
    "\n",
    "#     Miss attack Untargeted\n",
    "    \n",
    "    t1.atk_params.set_params(\n",
    "        batch_size=batch_size, \n",
    "        iteration = 10,\n",
    "        target = -1, \n",
    "        x_val_min = torch.min(data_x), \n",
    "        x_val_max = torch.max(data_x),\n",
    "        step_size = 0.01, \n",
    "        step_norm = \"inf\", \n",
    "        eps = eps, \n",
    "        eps_norm = 2\n",
    "    )\n",
    "    t1.generate_xadv(atk_type = \"pgd\")\n",
    "    t1.send_to_victims(victim_idxs)\n",
    "    logs_adv[adv_idx]['adv_miss'] = copy.deepcopy(t1.adv_acc_transfers)\n",
    "    logs_adv[adv_idx]['adv_similarities_untarget'] = copy.deepcopy(t1.adv_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Results Across clients \n",
    "metrics = ['orig_acc_transfers','orig_similarities','adv_acc_transfers','adv_similarities_target',\n",
    "           'adv_similarities_untarget','adv_target','adv_miss'] #,'metric_alignment']\n",
    "\n",
    "orig_acc = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "orig_sim = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "adv_acc = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "adv_sim_target = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "adv_sim_untarget = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "adv_target = np.zeros([len(victim_idxs),len(victim_idxs)])\n",
    "adv_miss = np.zeros([len(victim_idxs),len(victim_idxs)]) \n",
    "\n",
    "for adv_idx in range(len(victim_idxs)):\n",
    "    for victim in range(len(victim_idxs)):\n",
    "        orig_acc[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[0]][victim_idxs[victim]].data.tolist()\n",
    "        orig_sim[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[1]][victim_idxs[victim]].data.tolist()\n",
    "        adv_acc[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[2]][victim_idxs[victim]].data.tolist()\n",
    "        adv_sim_target[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[3]][victim_idxs[victim]].data.tolist()\n",
    "        adv_sim_untarget[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[4]][victim_idxs[victim]].data.tolist()\n",
    "        adv_target[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[5]][victim_idxs[victim]].data.tolist()\n",
    "        adv_miss[adv_idx,victim] = logs_adv[victim_idxs[adv_idx]][metrics[6]][victim_idxs[victim]].data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29 0.29 0.29 0.29 0.29 0.29 0.29 0.29 0.29 0.29]\n",
      " [0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30]\n",
      " [0.32 0.32 0.32 0.32 0.32 0.32 0.32 0.32 0.32 0.32]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30]\n",
      " [0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30]\n",
      " [0.41 0.41 0.41 0.41 0.41 0.41 0.41 0.41 0.41 0.41]\n",
      " [0.24 0.24 0.24 0.24 0.24 0.24 0.24 0.24 0.24 0.24]\n",
      " [0.32 0.32 0.32 0.32 0.32 0.32 0.32 0.32 0.32 0.32]\n",
      " [0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30]]\n"
     ]
    }
   ],
   "source": [
    "# Check Results\n",
    "print(adv_target[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90, 0.90, 0.90, 0.90, 0.90, 0.90, 0.90, 0.90, 0.90, 0.90],\n",
       "       [0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83],\n",
       "       [0.86, 0.86, 0.86, 0.86, 0.86, 0.86, 0.86, 0.86, 0.86, 0.86],\n",
       "       [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00],\n",
       "       [0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81],\n",
       "       [0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84],\n",
       "       [0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82, 0.82],\n",
       "       [0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81],\n",
       "       [0.86, 0.86, 0.86, 0.86, 0.86, 0.86, 0.86, 0.86, 0.86, 0.86],\n",
       "       [0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_acc[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.61 0.61 0.61 0.61 0.61 0.61 0.61 0.61 0.61 0.61]\n",
      " [0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58]\n",
      " [0.60 0.60 0.60 0.60 0.60 0.60 0.60 0.60 0.60 0.60]\n",
      " [1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00]\n",
      " [0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58]\n",
      " [0.63 0.63 0.63 0.63 0.63 0.63 0.63 0.63 0.63 0.63]\n",
      " [0.48 0.48 0.48 0.48 0.48 0.48 0.48 0.48 0.48 0.48]\n",
      " [0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64]\n",
      " [0.63 0.63 0.63 0.63 0.63 0.63 0.63 0.63 0.63 0.63]\n",
      " [0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58]]\n",
      "0.6197192803025245\n"
     ]
    }
   ],
   "source": [
    "print(adv_acc[:10, :10])\n",
    "print(np.sum(adv_acc) / (adv_acc.shape[0] * adv_acc.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"/home/ubuntu/Documents/jiarui/experiments/pFedDef/weights/cifar10/FedAvg_all_label_switch/pfeddef/acc.npy\", orig_acc)\n",
    "np.save(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg_adv/rep_atk/rep_scale0/eval/all_adv_acc.npy\", adv_acc)\n",
    "# np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/boosting80/eval/boosting80_all_acc.npy\")[:10,:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fedavg\n",
      "[[0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87]\n",
      " [0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81]\n",
      " [0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86]\n",
      " [1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00]\n",
      " [0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80]\n",
      " [0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84]\n",
      " [0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81]\n",
      " [0.79 0.79 0.79 0.79 0.79 0.79 0.79 0.79 0.79 0.79]\n",
      " [0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86]\n",
      " [0.82 0.82 0.82 0.82 0.82 0.82 0.82 0.82 0.82 0.82]]\n",
      "[[0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.78]\n",
      " [0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74]\n",
      " [0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65]\n",
      " [1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00]\n",
      " [0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70]\n",
      " [0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59]\n",
      " [0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.68]\n",
      " [0.61 0.61 0.61 0.61 0.61 0.61 0.61 0.61 0.61 0.61]\n",
      " [0.62 0.62 0.62 0.62 0.62 0.62 0.62 0.62 0.62 0.62]\n",
      " [0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73]]\n",
      "\n",
      "switch pair - 20 clients\n",
      "[[0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73]\n",
      " [0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71]\n",
      " [0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75]\n",
      " [0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83]\n",
      " [0.76 0.76 0.76 0.76 0.76 0.76 0.76 0.76 0.76 0.76]\n",
      " [0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73]\n",
      " [0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84]\n",
      " [0.77 0.77 0.77 0.77 0.77 0.77 0.77 0.77 0.77 0.77]]\n",
      "[[0.44 0.44 0.44 0.44 0.44 0.44 0.44 0.44 0.44 0.44]\n",
      " [0.36 0.36 0.36 0.36 0.36 0.36 0.36 0.36 0.36 0.36]\n",
      " [0.43 0.43 0.43 0.43 0.43 0.43 0.43 0.43 0.43 0.43]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.42 0.42 0.42 0.42 0.42 0.42 0.42 0.42 0.42 0.42]\n",
      " [0.56 0.56 0.56 0.56 0.56 0.56 0.56 0.56 0.56 0.56]\n",
      " [0.54 0.54 0.54 0.54 0.54 0.54 0.54 0.54 0.54 0.54]\n",
      " [0.39 0.39 0.39 0.39 0.39 0.39 0.39 0.39 0.39 0.39]\n",
      " [0.38 0.38 0.38 0.38 0.38 0.38 0.38 0.38 0.38 0.38]\n",
      " [0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50]]\n",
      "\n",
      "switch pair - 40 clients\n",
      "[[0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65]\n",
      " [0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65]\n",
      " [0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75]\n",
      " [0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66]\n",
      " [0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80]\n",
      " [0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65]\n",
      " [0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73]\n",
      " [0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85]\n",
      " [0.62 0.62 0.62 0.62 0.62 0.62 0.62 0.62 0.62 0.62]]\n",
      "[[0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06]\n",
      " [0.17 0.17 0.17 0.17 0.17 0.17 0.17 0.17 0.17 0.17]\n",
      " [0.20 0.20 0.20 0.20 0.20 0.20 0.20 0.20 0.20 0.20]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.13 0.13 0.13 0.13 0.13 0.13 0.13 0.13 0.13 0.13]\n",
      " [0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19]\n",
      " [0.15 0.15 0.15 0.15 0.15 0.15 0.15 0.15 0.15 0.15]\n",
      " [0.29 0.29 0.29 0.29 0.29 0.29 0.29 0.29 0.29 0.29]\n",
      " [0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " [0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11]]\n",
      "\n",
      "switch all\n",
      "[[0.44 0.44 0.44 0.44 0.44 0.44 0.44 0.44 0.44 0.44]\n",
      " [0.41 0.41 0.41 0.41 0.41 0.41 0.41 0.41 0.41 0.41]\n",
      " [0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50]\n",
      " [0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25]\n",
      " [0.37 0.37 0.37 0.37 0.37 0.37 0.37 0.37 0.37 0.37]\n",
      " [0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46]\n",
      " [0.53 0.53 0.53 0.53 0.53 0.53 0.53 0.53 0.53 0.53]\n",
      " [0.31 0.31 0.31 0.31 0.31 0.31 0.31 0.31 0.31 0.31]\n",
      " [0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47]\n",
      " [0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46]]\n",
      "[[0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28]\n",
      " [0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28 0.28]\n",
      " [0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35]\n",
      " [1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00]\n",
      " [0.23 0.23 0.23 0.23 0.23 0.23 0.23 0.23 0.23 0.23]\n",
      " [0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30]\n",
      " [0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47]\n",
      " [0.17 0.17 0.17 0.17 0.17 0.17 0.17 0.17 0.17 0.17]\n",
      " [0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25]\n",
      " [0.37 0.37 0.37 0.37 0.37 0.37 0.37 0.37 0.37 0.37]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nfedavg\")\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/pFedDef/eval/fedavg_all_acc.npy\")[:10,:10])\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/pFedDef/eval/fedavg_pair_acc.npy\")[:10,:10])\n",
    "\n",
    "print(\"\\nswitch pair - 20 clients\")\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/pFedDef/eval/switchPair20_all_acc.npy\")[:10,:10])\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/pFedDef/eval/switchPair20_pair_acc.npy\")[:10,:10])\n",
    "\n",
    "print(\"\\nswitch pair - 40 clients\")\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/switchPair40/eval/switchPair40_all_acc.npy\")[:10,:10])\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/switchPair40/eval/switchPair40_pair_acc.npy\")[:10,:10])\n",
    "\n",
    "print(\"\\nswitch all\")\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/pFedDef/eval/allSwitch_all_acc.npy\")[:10,:10])\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/pFedDef/eval/allSwitch_pair_acc.npy\")[:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all acc\n",
      "boost 40\n",
      "[[0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88]\n",
      " [0.79 0.79 0.79 0.79 0.79 0.79 0.79 0.79 0.79 0.79]\n",
      " [0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87]\n",
      " [1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00]\n",
      " [0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83]\n",
      " [0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87]\n",
      " [0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80]\n",
      " [0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80]\n",
      " [0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85]\n",
      " [0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.78]]\n",
      "boost 80\n",
      "[[0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87]\n",
      " [0.82 0.82 0.82 0.82 0.82 0.82 0.82 0.82 0.82 0.82]\n",
      " [0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85 0.85]\n",
      " [1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00]\n",
      " [0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83]\n",
      " [0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84]\n",
      " [0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81]\n",
      " [0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80]\n",
      " [0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86]\n",
      " [0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84]]\n",
      "boost 160\n",
      "[[0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88]\n",
      " [0.82 0.82 0.82 0.82 0.82 0.82 0.82 0.82 0.82 0.82]\n",
      " [0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84]\n",
      " [1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00]\n",
      " [0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83]\n",
      " [0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86 0.86]\n",
      " [0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80]\n",
      " [0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80 0.80]\n",
      " [0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83]\n",
      " [0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81 0.81]]\n",
      "pair acc\n",
      "boost 40\n",
      "[[0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.78]\n",
      " [0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64]\n",
      " [0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70]\n",
      " [1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00]\n",
      " [0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70]\n",
      " [0.67 0.67 0.67 0.67 0.67 0.67 0.67 0.67 0.67 0.67]\n",
      " [0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.68]\n",
      " [0.63 0.63 0.63 0.63 0.63 0.63 0.63 0.63 0.63 0.63]\n",
      " [0.62 0.62 0.62 0.62 0.62 0.62 0.62 0.62 0.62 0.62]\n",
      " [0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71]]\n",
      "boost 80\n",
      "[[0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72]\n",
      " [0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72]\n",
      " [0.57 0.57 0.57 0.57 0.57 0.57 0.57 0.57 0.57 0.57]\n",
      " [1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75]\n",
      " [0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59 0.59]\n",
      " [0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74 0.74]\n",
      " [0.56 0.56 0.56 0.56 0.56 0.56 0.56 0.56 0.56 0.56]\n",
      " [0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50]\n",
      " [0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73 0.73]]\n",
      "boost 160\n",
      "[[0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83]\n",
      " [0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72 0.72]\n",
      " [0.55 0.55 0.55 0.55 0.55 0.55 0.55 0.55 0.55 0.55]\n",
      " [1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00]\n",
      " [0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71]\n",
      " [0.67 0.67 0.67 0.67 0.67 0.67 0.67 0.67 0.67 0.67]\n",
      " [0.69 0.69 0.69 0.69 0.69 0.69 0.69 0.69 0.69 0.69]\n",
      " [0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71]\n",
      " [0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50 0.50]\n",
      " [0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71 0.71]]\n"
     ]
    }
   ],
   "source": [
    "print(\"all acc\")\n",
    "# print(\"boost 20\")\n",
    "# print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/boosting20/eval/boosting20_all_acc.npy\")[:10,:10])\n",
    "print(\"boost 40\")\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/boosting40/eval/boosting40_all_acc.npy\")[:10,:10])\n",
    "print(\"boost 80\")\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/boosting80/eval/boosting80_all_acc.npy\")[:10,:10])\n",
    "print(\"boost 160\")\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/boosting160/eval/boosting160_all_acc.npy\")[:10,:10])\n",
    "print(\"pair acc\")\n",
    "# print(\"boost 20\")\n",
    "# print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/boosting20/eval/boosting20_pair_acc.npy\")[:10,:10])\n",
    "print(\"boost 40\")\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/boosting40/eval/boosting40_pair_acc.npy\")[:10,:10])\n",
    "print(\"boost 80\")\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/boosting80/eval/boosting80_pair_acc.npy\")[:10,:10])\n",
    "print(\"boost 160\")\n",
    "print(np.load(\"/home/ubuntu/Documents/jiarui/experiments/FedAvg/cifar10/boosting160/eval/boosting160_pair_acc.npy\")[:10,:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33],\n",
       "       [0.33, 0.33, 0.33]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypath = \"/home/ubuntu/Documents/jiarui/experiments/oriCode/testFAT/pfeddef/weights\"\n",
    "np.load(f\"{mypath}/train_client_weights.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
